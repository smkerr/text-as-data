---
title: "Assignment 4"
author: "Steve Kerr (211924)"
date: "2023-10-23"
output: 
  pdf_document:
    keep_tex: true
    citation_package: natbib
header-includes:
- \usepackage{booktabs}
- \usepackage{xcolor}

extra_dependencies: ["hyperref","booktabs"]
urlcolor: blue
bibliography: ../presentation-resources/MyLibrary.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this assignment, you are asked to use topic modelling to investigate manifestos from the manifesto project maintained by [WZB](https://manifesto-project.wzb.eu/). You can either use the UK manifestos we looked at together in class, or collect your own set of manifestos by choosing the country/countries, year/years and party/parties you are interested in. You should produce a report which includes your code, that addresses the following aspects of creating a topic model, making sure to answer the questions below.

This time, you will be assessed not only on whether the code gets the right result, but on how you understand and communicate your understanding of the modelling process and how this can answer your research question. The best research question is one that is interesting and answerable, but the most important thing is that the research question is answerable with the methods you choose.

You will also be assessed on the presentation of your results, and on the concision and readability of your code.

```{r}
# load packages
pacman::p_load(
  dplyr, 
  here,
  lubridate,
  manifestoR,
  readr,
  tidyr
  )
```

## 1. Data acquisition, description, and preparation

Bring together a dataset from the WZB.

```{r}
# define countries
countries <- c("Australia", "Canada", "South Africa", "New Zealand", "United Kingdom", "United States") # English-speaking countries

# load codebook
ref_df <- read_csv(here("Assignments_SK/Assignment-4/docs/documents_MPDataset_MPDS2023a.csv")) |> 
  filter(countryname %in% countries) |>
  select(country:partyname) |> 
  distinct()

# define file path for data
data_path <- here("Assignments_SK/Assignment-4/data/corpus.rds") 

# download data if not yet downloaded
if (!file.exists(data_path)) {
  
  # set API key
  mp_setapikey(here("Assignments_SK/Assignment-4/manifesto_apikey.txt"))
  
  # query data
  corpus <- mp_corpus(countryname %in% countries & edate > as_date("2000-01-01"))
  
  # save data
  saveRDS(corpus, here("Assignments_SK/Assignment-4/data/corpus.rds"))
  
} else {
  
  # load data
  corpus <- read_rds(data_path)
  
}

# inspect corupus
corpus
```

```{r}
# explore data
head(content(corpus[[1]])) # view beginning of text of first manifesto
table(codes(corpus)) # count codes of all manifestos
meta(corpus[[1]]) # view meta data of first manifesto
```

What years, countries and parties are included in the dataset? How many texts do you have for each of these?

```{r}
# initialize empty df
meta_df <- tibble()

# for each doc in corpus...
for (i in seq_along(corpus)) {
  
  # extract meta data 
  meta_doc <- meta(corpus[[i]]) |> 
    unlist() |> 
    as_tibble() |> 
    bind_cols(
      var = meta(corpus[[i]]) |> # extract var names
        unlist() |> 
        names()
      ) |> 
    pivot_wider(names_from = "var", values_from = "value")
  
  # append to meta data df
  meta_df <- meta_df |> 
    bind_rows(meta_doc)
}

glimpse(meta_df)
janitor::tabyl(meta_df$is_copy_of)
# identify edge cases
meta_df |> 
  filter(has_eu_code == "TRUE")
meta_df |> 
  filter(is.na(is_primary_doc))
meta_df |> 
  filter(annotations == "FALSE")
janitor::tabyl(meta_df$handbook) # TODO: check out handbooks
janitor::tabyl(meta_df$is_copy_of) # TODO: de-duplicate copies 

meta_df$party |> unique() 
ref_df$party |> unique()

# combine with codebook
meta_df |> 
  # TODO: de-duplicate copies
  select(id, party_id = party, date, language, source, is_copy_of) |>
  mutate(
    party_id = as.numeric(party_id),
    date = as_date(date, format = "%Y%m")
    ) |> 
  left_join(ref_df, by = join_by(party_id == party))

```

Prepare your data for topic modelling by creating a document feature matrix. Describe the choices you make here, and comment on how these might affect your final result.

```{r}
# pre-processing
corpus_cleaned <- tm_map(corpus, removePunctuation)
corpus_nostop <- tm_map(corpus_cleaned, removeWords, stopwords("english"))
```

## 2. Research question

Describe a research question you want to explore with topic modelling. Comment on how answerable this is with the methods and data at your disposal.

```{r}

```

## 3. Topic model development

Create a topic model using your data. Explain to a non-specialist what the topic model does. Comment on the choices you make here in terms of hyperparameter selection and model choice. How might these affect your results and the ability to answer your research question?

```{r}

```

## 4. Topic model description

Describe the topic model. What topics does it contain? How are these distributed across the data?

```{r}

```

## 5. Answering your research question

Use your topic model to answer your research question by showing plots or statistical results. Discuss the implications of what you find, and any limitations inherent in your approach. Discuss how the work could be improved upon in future research.

```{r}

```

# Sources

-   Lehmann, Pola / Franzmann, Simon / Burst, Tobias / Regel, Sven / Riethmüller, Felicia / Volkens, Andrea / Weßels, Bernhard / Zehnter, Lisa (2023): The Manifesto Data Collection. Manifesto Project (MRG/CMP/MARPOR). Version 2023a. Berlin: Wissenschaftszentrum Berlin für Sozialforschung (WZB) / Göttingen: Institut für Demokratieforschung (IfDem). <https://doi.org/10.25522/manifesto.mpds.2023a>

# Resources

-   [`manifestoR` vignette](https://cran.r-project.org/web/packages/manifestoR/vignettes/manifestoRworkflow.pdf)
