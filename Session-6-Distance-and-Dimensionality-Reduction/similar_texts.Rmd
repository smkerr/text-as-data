---
title: "Getting similar texts"
author: "Max Callaghan"
date: "2023-10-16"
output: html_document
---

We know how to calculate the similarity of texts from our data frame, but how do we get information about which texts we are comparing

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We first need to make sure we give each item in our dataframe a unique ID which we can use to identify it.

```{r echo=TRUE, include=TRUE, message=FALSE}
library(readr)
df <- read_csv("data/uk_manifestos.csv")
df$id <- as.character(seq(1,length(df$text)))
df
```

To make it easier to access data using ids later, we can create a corpus object, and tell quanteda to use our ID column as the names of the documents

```{r echo=TRUE, include=TRUE, message=FALSE}
library(quanteda)
corp <- corpus(df)
docnames(corp) <- df$id
```

We can pass this corpus object to our usual functions for creating a document feature matrix, then calculate the similarity matrix.

```{r echo=TRUE, include=TRUE, message=FALSE}
library(quanteda.textstats)
dfmat <- corp %>% tokens(remove_punc=TRUE) %>%
  tokens_remove(pattern=stopwords("en")) %>%
  dfm() %>%
  dfm_trim(min_termfreq=5) %>%
  dfm_tfidf()

sim_mat <- textstat_simil(dfmat, method="cosine", min_simil=-1)
sim_df <- as.data.frame(sim_mat, diag=TRUE, upper=TRUE)


```

We define an index for the text we want to find similar texts to, and get the similarity comparisons that compare to that document.
After sorting and taking the first 5 documents, we can merge (left_join) with our original dataset using the id column.

```{r echo=TRUE, include=TRUE, message=FALSE}
target_text <- 1335
print(df$text[target_text])

library(dplyr)
similar_docs <- sim_df %>% filter(document1==target_text) %>%
  arrange(desc(cosine)) %>%
  head(5) %>%
  left_join(df, by=c("document2"="id"))

similar_docs

```

## Embeddings

Let's embed the documents and plot them.

```{r echo=TRUE, include=TRUE, message=FALSE}
library(uwot)
library(lsa)
library(ggplot2)

embeddings <- umap(as.matrix(dfmat))

df$x <- embeddings[,1]
df$y <- embeddings[,2]

colordict <- c(
  "Labour"="red","LibDems"="yellow",
  "Conservatives"="Blue","Greens"="green")

p <- ggplot(df, aes(x, y, fill=party)) + 
  geom_point(color="grey", shape=21, size=0.5) + 
  scale_fill_manual(values=colordict) + 
  theme_bw() +
  coord_fixed()
p

```

We can compare the same documents in our embedding space by calculating the 
cosine similarity, but this has little meaning in our embedding space, as all documents
that are one a single straight line will have a similarity of 1. Euclidean distance
tells us how far apart the points are in the 2 dimensional space.

```{r echo=TRUE, include=TRUE, message=FALSE}

print(df$text[target_text])

dist_matrix <- as.matrix(dist(embeddings))

for (i in 1:nrow(similar_docs)) {
  comp_id <- as.numeric(similar_docs[i,"document2"])
  comp_text <- df$text[comp_id]
  multi_sim <- similar_docs[i,"cosine"]
  embed_sim <- cosine(embeddings[target_text,], embeddings[comp_id,])

  writeLines(paste0(
    "\nDocument: ",
    comp_text,
    "\nmultidimensional cosine similarity: ",
    round(multi_sim,2),
    "\nembedding cosine similarity: ",
    round(embed_sim,2),
    "\nembedding euclidean distance:  ",
    round(dist_matrix[target_text,comp_id],2)
  ))
} 
```

If we plot the documents in the embedded space, colouring according to how similar they are to our target document in the multidimensional space, we can see that similar documents are indeed rather closer together.

```{r echo=TRUE, include=TRUE, message=FALSE}


target_sim_df <-  sim_df %>% filter(document1==target_text) %>%
  arrange(desc(cosine)) %>%
  left_join(df, by=c("document2"="id"))

p <- ggplot(target_sim_df, aes(x, y, fill=cosine)) + 
  geom_point(color="grey", shape=21, size=2) + 
  scale_fill_distiller(palette="YlGnBu", direction = 1) + 
  theme_bw() +
  coord_fixed()
p
```
