---
title: "Regex example - net zero"
author: "Max Callaghan"
date: "2023-10-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(reticulate)
use_python("/usr/bin/python3.10")

#def.chunk.hook  <- knitr::knit_hooks$get("chunk")
#knitr::knit_hooks$set(chunk = function(x, options) {
#  x <- def.chunk.hook(x, options)
#  paste0("\n \\", "tiny","\n\n", x, "\n\n \\normalsize")
#})

```

## Load data

```{r echo=TRUE, include=TRUE, cache=TRUE}
library(readr)
library(stringr)

library(jsonlite)
library(dplyr)
library(dotenv)
library(httr)
load_dot_env(".env")
r <- GET(
  "https://api.openalex.org/works?search=%22net%20zero%22&per-page=200",
  add_headers(email=Sys.getenv("email"))
)
data <- fromJSON(content(r, "text"))
rdata <- fromJSON(content(r, "text"), simplifyVector=FALSE)
uninvert <- function(aii) { # turn the abstract inverted index into an abstract
  if (is.null(aii$abstract_inverted_index)) {
    return(NULL)
  }
  x <- stack(aii$abstract_inverted_index) 
  words <- x[order(x$values),"ind"]
  return(paste(words, collapse=" "))
}

df <- cbind(
  select(data$results, where(is.character)), 
  select(data$results, where(is.numeric))
)
df$abstract <- sapply(rdata$results, uninvert)
```

## Load data in python

```{python echo=TRUE, include=TRUE}
import requests
import pandas as pd
r = requests.get("https://api.openalex.org/works?search=%22net%20zero%22&per-page=200")
res = r.json()
def uninvert_abstract(aii):
    if aii is None:
        return None
    word_index = list(aii.items())
    word_index = sorted(word_index, key=lambda x: x[1])
    return " ".join(map(lambda x: x[0], word_index))
keep_fields = ["id","doi","title","publication_year"]
work_dicts = []
for work in res["results"]:
    # Get the basic fields we want
    work_min = {k: work[k] for k in keep_fields}
    # uninvert the abstract
    work_min["abstract"] = uninvert_abstract(work["abstract_inverted_index"])
    # put the authors into a single string
    authors = [author["author"]["display_name"] for author in work["authorships"]]
    work_min["authors"] = ", ".join([a for a in authors if a is not None])
    work_dicts.append(work_min)
df = pd.DataFrame.from_dict(work_dicts)
```

Let's start with a simple pattern that retrieves years in the 21st century. 
This means a 2 and a 0, followed by two more digits

```{r echo=TRUE, include=TRUE, cache=TRUE}
pat <- "20[0-9]{2}"
table(str_extract(df$abstract,pattern = regex(pat)))
```


Let's start with a simple pattern that retrieves years in the 21st century. 
This means a 2 and a 0, followed by two more digits

```{python echo=TRUE, include=TRUE}
import re

pat = "20[0-9]{2}"

def extract_years(x, pattern):
    m = re.search(pat,x)
    if m is not None:
        return m.group(0)

df['years'] = df['abstract'].astype(str).apply(extract_years, pattern=pat)
df.groupby('years')['id'].nunique()
```

OK, let's now match all dates in the 2030s, 40s, 50s, etc. but only 2024 onwards from the 20s, and no dates from the 10s or 00s

```{r echo=TRUE, include=TRUE, cache=TRUE}
pat <- "20((2[4-9]{1})|([3-9]{1}[0-9]{1}))"
table(str_extract(df$abstract,pattern = regex(pat)))
```

```{python echo=TRUE, include=TRUE, cache=TRUE}
pat = "20((2[4-9]{1})|([3-9]{1}[0-9]{1}))"

df['years'] = df['abstract'].astype(str).apply(extract_years, pattern=pat)
df.groupby('years')['id'].nunique()
```

Finally, let us extend this to the additional centuries (up to the year 10,000)

```{r echo=TRUE, include=TRUE, cache=TRUE}
pat <- "20((2[4-9]{1})|([3-9]{1}[0-9]{1}))|2[1-9]{1}[0-9]{2}"
table(str_extract(df$abstract,pattern = regex(pat)))
```

```{python echo=TRUE, include=TRUE, cache=TRUE}
pat = "20((2[4-9]{1})|([3-9]{1}[0-9]{1}))|2[1-9]{1}[0-9]{2}"

df['years'] = df['abstract'].astype(str).apply(extract_years, pattern=pat)
df.groupby('years')['id'].nunique()
```